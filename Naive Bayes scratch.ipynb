{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73ab618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c708ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##training data\n",
    "\n",
    "X = np.array([\n",
    "    [2,1,0,0,0,0],\n",
    "    [2,0,1,0,0,0],\n",
    "    [1,0,0,1,0,0],\n",
    "    [1,0,0,0,1,1]\n",
    "])\n",
    "y = np.array([0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e04a678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ccfc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([2, 1, 0, 0, 0, 0]), array([2, 0, 1, 0, 0, 0]), array([1, 0, 0, 1, 0, 0])], [array([1, 0, 0, 0, 1, 1])]]\n"
     ]
    }
   ],
   "source": [
    "separated = []\n",
    "for c in np.unique(y): #loop through each class\n",
    "    inner = []\n",
    "    for x, t in zip(X,y): #loop through each record\n",
    "        if t == c:\n",
    "            inner.append(x)\n",
    "    separated.append(inner)\n",
    "print (separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620fe538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee858dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([2, 1, 0, 0, 0, 0]), array([2, 0, 1, 0, 0, 0]), array([1, 0, 0, 1, 0, 0])], [array([1, 0, 0, 0, 1, 1])]]\n"
     ]
    }
   ],
   "source": [
    "separated = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)]\n",
    "print (separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d09f7e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4bda404",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_samples = X.shape[0] #number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be7a4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "separated = [[x for x,t in zip(X,y) if t == c] for c in np.unique(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e1e792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_log_prior_ = [np.log(len(all_samples_in_class)/count_samples) for all_samples_in_class in separated] #priors\n",
    "#list of priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad20d308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2876820724517809, -1.3862943611198906]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_log_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad6c18a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1 1 1 0 0]\n",
      "[1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "count = []\n",
    "for all_samples_in_class in separated:\n",
    "    print(np.array(all_samples_in_class).sum(axis=0)) #turn list into numpy then take the sum along each column aka word\n",
    "count = np.array([np.array(all_samples_in_class).sum(axis=0) for all_samples_in_class in separated])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b678f8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1 1 1 0 0]\n",
      " [1 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c210bd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8],\n",
       "       [3]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.sum(axis=1)[np.newaxis].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0ae9534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.625     , 0.125     , 0.125     , 0.125     , 0.        ,\n",
       "        0.        ],\n",
       "       [0.33333333, 0.        , 0.        , 0.        , 0.33333333,\n",
       "        0.33333333]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/count.sum(axis=1)[np.newaxis].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86be329",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''get the number of samples\n",
    "\n",
    "create an array of arrays. So each element is the list of records we have for each class.\n",
    "\n",
    "prior = create an array of the priors. so each prior is going to be the length of the inside array right divided by\n",
    "the first calculation.\n",
    "\n",
    "likelihood is the count of each word. so turn the array into numpy array and then take the sum across the 0-axis. then turn\n",
    "that into an array. \n",
    "\n",
    "predict so the posterior is likelihood times the x-record + 1-likelihood times absolute value of x-1. so\n",
    "if the word exists then x-1 is 0 so 1-likelihood is 0. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9f41cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNB_mine(object):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha=alpha\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        count_samples = X.shape[0]\n",
    "        records_by_class = [[x for x,label in zip(X,y) if label == target] for target in np.unique(y)]\n",
    "        self.class_log_prior_ = [np.log(len(records)/count_samples) for records in records_by_class]\n",
    "        word_sum = np.array([np.array(records).sum(axis=0) for records in records_by_class]) + self.alpha\n",
    "        count_sum = word_sum.sum(axis=1)\n",
    "        self.feature_log_prob_ = np.log(word_sum / word_sum.sum(axis=1)[np.newaxis].T)\n",
    "        return self\n",
    "    def predict_log_proba(self,X):\n",
    "        print([(self.feature_log_prob_ * x).sum(axis=1) + self.class_log_prior_ for x in X])\n",
    "        return [(self.feature_log_prob_ * x).sum(axis=1) + self.class_log_prior_ for x in X]\n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_log_proba(X), axis=1)\n",
    "    def feature_log_prob_(self):\n",
    "        return self.feature_log_prob_\n",
    "    def class_log_prior_(self):\n",
    "        return self.class_log_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "df329cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-911.99414188]\n",
      "[[-68.31883031 -69.89100067   0.         -76.59265374 -85.02998333\n",
      "  -83.71000399]]\n",
      "[1 2 3 4 5 6]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from scipy.special import logsumexp\n",
    "rng = np.random.RandomState(1)\n",
    "X = rng.randint(5, size=(6, 100))\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "# print(clf.predict_log_proba(X[2:3]))\n",
    "# print(clf.predict(X[2:3]))\n",
    "# print(clf.feature_log_prob_*X[2:3])\n",
    "jll = safe_sparse_dot(X[2:3], clf.feature_log_prob_.T) + clf.class_log_prior_\n",
    "log_prob_x = logsumexp(jll, axis=1)\n",
    "print(log_prob_x)\n",
    "print( jll - np.atleast_2d(log_prob_x).T)\n",
    "print(clf.classes_)\n",
    "print(clf.classes_[np.argmax(jll, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e618085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.791759469228055, -1.791759469228055, -1.791759469228055, -1.791759469228055, -1.791759469228055, -1.791759469228055]\n",
      "[-911.99414188]\n",
      "[[-68.31883031 -69.89100067   0.         -76.59265374 -85.02998333\n",
      "  -83.71000399]]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "clf2 = MultinomialNB_mine()\n",
    "clf2.fit(X, y)\n",
    "# print(clf2.feature_log_prob_==clf.feature_log_prob_)\n",
    "# print(clf2.feature_log_prob_[2][3])\n",
    "# print(clf.feature_log_prob_[2][3])\n",
    "# print(clf.predict(X[2:3]))\n",
    "# print(clf2.feature_log_prob_*X[2:3])\n",
    "print(clf2.class_log_prior_)\n",
    "jll = safe_sparse_dot(X[2:3], clf2.feature_log_prob_.T) + clf2.class_log_prior_\n",
    "log_prob_x = logsumexp(jll, axis=1)\n",
    "print (log_prob_x)\n",
    "print( jll - np.atleast_2d(log_prob_x).T)\n",
    "print(np.unique(y)[np.argmax(jll, axis=1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c36b7",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "01683e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB_Mine(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        records_by_class = [[x for x, label in zip(x,y) if label == target] for target in np.unique(y)]\n",
    "        self.model = np.array([np.c_[np.mean(records,axis=0),np.std(records, axis=0)] for records in records_by_class])\n",
    "        return self\n",
    "    def _prob(self, x, mean, std):\n",
    "        exponent = np.exp(- ((x-mean)**2 / (2* std**2)))\n",
    "        return np.log(exponent / (np.sqrt(2*np.pi) * std))\n",
    "\n",
    "    def predict_log_proba_(self, X):\n",
    "        return [[sum(self._prob(i, *s) for s,i in zip(statistics, x)) for statistics in self.model] for x in X]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_log_proba_(X), axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return sum(self.predict(X)==y) / len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "18602045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[[-5.05653266e-08 -1.67999998e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "print(clf.predict_log_proba([[-0.8,-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "38fe8141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[-3.0568998348165355, -5.006899834816537]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "clf = GaussianNB_Mine()\n",
    "clf.fit(X, Y)\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "print(clf.predict_log_proba_([[-0.8,-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8af8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:study] *",
   "language": "python",
   "name": "conda-env-study-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
